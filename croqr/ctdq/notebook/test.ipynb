{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eef2bfa-2b41-4a6d-94b8-ea4c1cbab883",
   "metadata": {},
   "source": [
    "### test runexp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7def4862-0f4c-4320-9a24-76149bb7cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from croqr.common.config import LOCAL_DATA_DIR \n",
    "from croqr.ctdq.fs import MyNN, MyLogisticRegression, runselector\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from croqr.ctdq.fs import getfeaturenames\n",
    "from sklearn.linear_model import LogisticRegression,Lasso,LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import get_scorer,balanced_accuracy_score,mean_squared_error,r2_score,cohen_kappa_score, confusion_matrix,f1_score,classification_report,roc_auc_score,roc_curve,auc,recall_score,precision_score,precision_recall_curve,average_precision_score\n",
    "from sklearn.model_selection import cross_val_score,RandomizedSearchCV\n",
    "DF=pd.DataFrame\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e34c9a94-3afa-4c04-9c5c-f5a4559fc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample = '1Min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82f30360-0c6a-4efc-8f55-fca143582656",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffilename='dfbt'+resample+'f.pkl'#'dfbt30sf.pkl' dfbt30Sfandinter.pkl\n",
    "pd.set_option(\"display.precision\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de4bc4c-c3a0-45d7-bcc9-191efb9159b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(os.path.join(LOCAL_DATA_DIR, dffilename)).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09023bf-da95-4e92-a15f-24558dd8e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3e00ad-c770-41d9-a33c-569354beeb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a1d043-9077-4823-acc7-b86db6be7f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfcols=['inst_id', 'provider_id', 'event_date', 'exch_ts', 'local_ts', 'bestb', 'besta', 'amb', 'm', 'bv1', 'av1', 'vimb1', 'bc1', 'ac1', 'cimb1', 'vwap1', 'bv5', 'av5', 'vimb5', 'bc5', 'ac5', 'cimb5', 'vwap5', 'bv20', 'av20', 'vimb20', 'bc20', 'ac20', 'cimb20', 'vwap20', 'bv25', 'av25', 'vimb25', 'bc25', 'ac25', 'cimb25', 'vwap25', 'ybb', 'ybs', 'qimb', 'signimb', 'vwap', 'qb', 'qs', 'nb', 'ns', 'o', 'h', 'l', 'c', 'qbp', 'qsp', 'nbp', 'nsp', 'r', 'dpinbuy', 'dpinsell', 'dpin', 'dpins', 'hml', 'rl+1.c', 'ycb', 'ycs', 'noise1', 'noise2', 'rl-1.m', 'rl-1.amb', 'rl-1.vwap1', 'rl-1.vwap5', 'rl-1.c', 'rl-1.qimb', 'rl-1.signimb', 'rl-1.vwap', 'rl-1.qb', 'rl-1.qs', 'rl-1.qbp', 'rl-1.qsp', 'rl-1.nbp', 'rl-1.nsp', 'rl-1.dpinbuy', 'rl-1.dpinsell', 'rl-1.dpin', 'rl-1.dpins', 'rl-1.hml', 'ra-1.vimb1', 'ra-1.cimb1', 'ra-1.cimb5', 'ra-1.vimb20', 'ra-1.signimb', 'ra-1.r', 'qrandn2,15.rl-1.m', 'qrandn2,15.rl-1.amb', 'qrandn2,15.rl-1.vwap1', 'qrandn2,15.rl-1.vwap5', 'qrandn2,15.rl-1.c', 'qrandn2,15.rl-1.qimb', 'qrandn2,15.rl-1.signimb', 'qrandn2,15.rl-1.vwap', 'qrandn2,15.rl-1.qb', 'qrandn2,15.rl-1.qs', 'qrandn2,15.rl-1.qbp', 'qrandn2,15.rl-1.qsp', 'qrandn2,15.rl-1.nbp', 'qrandn2,15.rl-1.nsp', 'qrandn2,15.rl-1.dpinbuy', 'qrandn2,15.rl-1.dpinsell', 'qrandn2,15.rl-1.dpin', 'qrandn2,15.rl-1.dpins', 'qrandn2,15.rl-1.hml', 'qrandn2,15.ra-1.vimb1', 'qrandn2,15.ra-1.cimb1', 'qrandn2,15.ra-1.cimb5', 'qrandn2,15.ra-1.vimb20', 'qrandn2,15.ra-1.signimb', 'qrandn2,15.ra-1.r', 'qrandn5,100.rl-1.m', 'qrandn5,100.rl-1.amb', 'qrandn5,100.rl-1.vwap1', 'qrandn5,100.rl-1.vwap5', 'qrandn5,100.rl-1.c', 'qrandn5,100.rl-1.qimb', 'qrandn5,100.rl-1.signimb', 'qrandn5,100.rl-1.vwap', 'qrandn5,100.rl-1.qb', 'qrandn5,100.rl-1.qs', 'qrandn5,100.rl-1.qbp', 'qrandn5,100.rl-1.qsp', 'qrandn5,100.rl-1.nbp', 'qrandn5,100.rl-1.nsp', 'qrandn5,100.rl-1.dpinbuy', 'qrandn5,100.rl-1.dpinsell', 'qrandn5,100.rl-1.dpin', 'qrandn5,100.rl-1.dpins', 'qrandn5,100.rl-1.hml', 'qrandn5,100.ra-1.vimb1', 'qrandn5,100.ra-1.cimb1', 'qrandn5,100.ra-1.cimb5', 'qrandn5,100.ra-1.vimb20', 'qrandn5,100.ra-1.signimb', 'qrandn5,100.ra-1.r', 'qrandn5,100.noise1', 'qrandn5,100.noise2']\n",
      "only floats=['inst_id', 'provider_id', 'exch_ts', 'local_ts', 'bestb', 'besta', 'amb', 'm', 'bv1', 'av1', 'vimb1', 'bc1', 'ac1', 'cimb1', 'vwap1', 'bv5', 'av5', 'vimb5', 'bc5', 'ac5', 'cimb5', 'vwap5', 'bv20', 'av20', 'vimb20', 'bc20', 'ac20', 'cimb20', 'vwap20', 'bv25', 'av25', 'vimb25', 'bc25', 'ac25', 'cimb25', 'vwap25', 'ybb', 'ybs', 'qimb', 'signimb', 'vwap', 'qb', 'qs', 'nb', 'ns', 'o', 'h', 'l', 'c', 'qbp', 'qsp', 'nbp', 'nsp', 'r', 'dpinbuy', 'dpinsell', 'dpin', 'dpins', 'hml', 'rl+1.c', 'ycb', 'ycs', 'noise1', 'noise2', 'rl-1.m', 'rl-1.amb', 'rl-1.vwap1', 'rl-1.vwap5', 'rl-1.c', 'rl-1.qimb', 'rl-1.signimb', 'rl-1.vwap', 'rl-1.qb', 'rl-1.qs', 'rl-1.qbp', 'rl-1.qsp', 'rl-1.nbp', 'rl-1.nsp', 'rl-1.dpinbuy', 'rl-1.dpinsell', 'rl-1.dpin', 'rl-1.dpins', 'rl-1.hml', 'ra-1.vimb1', 'ra-1.cimb1', 'ra-1.cimb5', 'ra-1.vimb20', 'ra-1.signimb', 'ra-1.r', 'qrandn2,15.rl-1.m', 'qrandn2,15.rl-1.amb', 'qrandn2,15.rl-1.vwap1', 'qrandn2,15.rl-1.vwap5', 'qrandn2,15.rl-1.c', 'qrandn2,15.rl-1.qimb', 'qrandn2,15.rl-1.signimb', 'qrandn2,15.rl-1.vwap', 'qrandn2,15.rl-1.qb', 'qrandn2,15.rl-1.qs', 'qrandn2,15.rl-1.qbp', 'qrandn2,15.rl-1.qsp', 'qrandn2,15.rl-1.nbp', 'qrandn2,15.rl-1.nsp', 'qrandn2,15.rl-1.dpinbuy', 'qrandn2,15.rl-1.dpinsell', 'qrandn2,15.rl-1.dpin', 'qrandn2,15.rl-1.dpins', 'qrandn2,15.rl-1.hml', 'qrandn2,15.ra-1.vimb1', 'qrandn2,15.ra-1.cimb1', 'qrandn2,15.ra-1.cimb5', 'qrandn2,15.ra-1.vimb20', 'qrandn2,15.ra-1.signimb', 'qrandn2,15.ra-1.r', 'qrandn5,100.rl-1.m', 'qrandn5,100.rl-1.amb', 'qrandn5,100.rl-1.vwap1', 'qrandn5,100.rl-1.vwap5', 'qrandn5,100.rl-1.c', 'qrandn5,100.rl-1.qimb', 'qrandn5,100.rl-1.signimb', 'qrandn5,100.rl-1.vwap', 'qrandn5,100.rl-1.qb', 'qrandn5,100.rl-1.qs', 'qrandn5,100.rl-1.qbp', 'qrandn5,100.rl-1.qsp', 'qrandn5,100.rl-1.nbp', 'qrandn5,100.rl-1.nsp', 'qrandn5,100.rl-1.dpinbuy', 'qrandn5,100.rl-1.dpinsell', 'qrandn5,100.rl-1.dpin', 'qrandn5,100.rl-1.dpins', 'qrandn5,100.rl-1.hml', 'qrandn5,100.ra-1.vimb1', 'qrandn5,100.ra-1.cimb1', 'qrandn5,100.ra-1.cimb5', 'qrandn5,100.ra-1.vimb20', 'qrandn5,100.ra-1.signimb', 'qrandn5,100.ra-1.r', 'qrandn5,100.noise1', 'qrandn5,100.noise2']\n"
     ]
    }
   ],
   "source": [
    "print(f\"dfcols={list(df.columns)}\")\n",
    "#keep only float columns,  not time\n",
    "#ipdb.set_trace()\n",
    "df=df.select_dtypes(include=[np.float,np.int,np.int64,np.int32])\n",
    "print(f\"only floats={list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e6a96af-d8d0-4c3c-988a-8134a906160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs=getfeaturenames('y', df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ce38ded-acef-4ebf-b504-4152533852a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yrs=['rl+1.c']\n"
     ]
    }
   ],
   "source": [
    "yrs=[yr for yr in yrs if df[yr].nunique()>10] # yr stand for?\n",
    "print(f\"yrs={yrs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f337414-c027-4ee1-a3dc-e73259ace47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['inst_id', 'provider_id', 'exch_ts', 'local_ts', 'bestb', 'besta',\n",
       "       'amb', 'm', 'bv1', 'av1',\n",
       "       ...\n",
       "       'qrandn5,100.rl-1.dpins', 'qrandn5,100.rl-1.hml',\n",
       "       'qrandn5,100.ra-1.vimb1', 'qrandn5,100.ra-1.cimb1',\n",
       "       'qrandn5,100.ra-1.cimb5', 'qrandn5,100.ra-1.vimb20',\n",
       "       'qrandn5,100.ra-1.signimb', 'qrandn5,100.ra-1.r', 'qrandn5,100.noise1',\n",
       "       'qrandn5,100.noise2'],\n",
       "      dtype='object', length=141)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "681a2879-ce0b-405f-a70e-1d67400cdd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rl+1.c']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98211c69-44ec-410b-b078-ae95907a4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsraw = ['m', 'amb', 'nbp', 'dpinsell', 'qbp', 'dpin', 'qsp', 'qimb', 'signimb', 'hml', 'vimb1',\n",
    "                                'vimb5', 'cimb1', 'cimb5', 'vwap1',\n",
    "                                'r']\n",
    "xs = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6fc85e44-c1f2-48b9-ac13-632ebae55ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsraw = getfeaturenames('raw', df.columns, xsraw=xsraw)\n",
    "xsq3 = getfeaturenames('q3', df.columns, xsraw=xsraw)\n",
    "xsq95 = getfeaturenames('q95', df.columns, xsraw=xsraw)\n",
    "\n",
    "xsall = getfeaturenames('all', df.columns)\n",
    "xsinteract = getfeaturenames('interact', df.columns)\n",
    "y = 'ycb'\n",
    "\n",
    "models = [\"log\", \"lin\", \"xgb\", \"nn\", \"plog\", \"plin\", \"pn\",'xgbc','xgbrf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3dc6b2b-bde9-4733-8ff2-4a3144b2325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = {'all': xsall, 'raw': xsraw, 'q3': xsq3, 'q95': xsq95}[xs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad3d579b-34f9-4249-83ba-87a492435dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141    100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "135e98cb-b0a4-4290-8555-55baf8452444",
   "metadata": {},
   "outputs": [],
   "source": [
    "optiter = 1\n",
    "cv = 2\n",
    "df = df.iloc[:200].dropna()\n",
    "dftrain = df.iloc[:int(0.8 * len(df))]\n",
    "dftest = df.iloc[-int(0.1 * len(df)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b4731bbe-6718-4e3a-b89a-e6b031aff1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m',\n",
       " 'dpin',\n",
       " 'qimb',\n",
       " 'amb',\n",
       " 'cimb1',\n",
       " 'dpinsell',\n",
       " 'signimb',\n",
       " 'cimb5',\n",
       " 'hml',\n",
       " 'vimb5',\n",
       " 'r',\n",
       " 'vimb1',\n",
       " 'qbp',\n",
       " 'qsp',\n",
       " 'nbp',\n",
       " 'vwap1']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c5732-0478-45b8-bf5f-fd466d6b212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrainxsraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "10978d65-8384-4029-ae67-2c0258e1fbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "for yr in yrs:\n",
    "    olstrain = dftrain[xsraw].ffill()\n",
    "    olstest = dftest[xsraw].ffill()\n",
    "\n",
    "    ols = LinearRegression()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(olstrain)\n",
    "    ols.fit(scaler.transform(olstrain), dftrain[yr])\n",
    "    r2is = ols.score(scaler.transform(olstrain), dftrain[yr])\n",
    "    r2os = ols.score(scaler.transform(olstest), dftest[yr])\n",
    "    #    ipdb.set_trace()\n",
    "\n",
    "    if yr == 'rl+1.c' and y == 'ycb':\n",
    "        ypis = (ols.predict(scaler.transform(olstrain)) > 0).astype(int)\n",
    "        ypos = (ols.predict(scaler.transform(olstest)) > 0).astype(int)\n",
    "        f1is = f1_score(dftrain[y], ypis)\n",
    "        f1os = f1_score(dftest[y], ypos)\n",
    "\n",
    "\n",
    "    if yr == 'rl+1.c' and y == 'ycs':\n",
    "        ypis = (ols.predict(scaler.transform(olstrain)) < 0).astype(int)\n",
    "        ypos = (ols.predict(scaler.transform(olstest)) < 0).astype(int)\n",
    "        f1is = f1_score(dftrain[y], ypis)\n",
    "        f1os = f1_score(dftest[y], ypos)\n",
    "\n",
    "print(f1is, f1os)\n",
    "    # among the metric, what metrix do you need to use? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56dc56ce-91a4-48b2-88e4-59b7d5e02c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6666666666666667, 0.3333333333333333)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1is, f1os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a2844d15-8fd5-4996-83e6-255b11b3c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wang\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning:\n",
      "\n",
      "The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002120F1CDAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wang\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning:\n",
      "\n",
      "The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002122ABEE5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wang\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning:\n",
      "\n",
      "The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rscv MyNN fixedparams={'scale_pos_weight': 10, 'output_bias': 0.9} bestscore=0.7199180747567844 bestparams={'nhidden2': 1, 'nhidden1': 1, 'nfirst': 10, 'lr': 0.1, 'epochs': 100, 'dropout': 0.2, 'batch_size': 10} \n",
      "   mean_test_score  std_test_score  \\\n",
      "0 0.7199180748     0.0102406554      \n",
      "\n",
      "                                                                                                     params  \n",
      "0  {'nhidden2': 1, 'nhidden1': 1, 'nfirst': 10, 'lr': 0.1, 'epochs': 100, 'dropout': 0.2, 'batch_size': 10}  \n",
      "rscv \n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0 1.254441857    0.03261053562 0.06224167347    0.001146674156    \n",
      "\n",
      "  param_nhidden2 param_nhidden1 param_nfirst param_lr param_epochs  \\\n",
      "0  1              1              10          0.1       100           \n",
      "\n",
      "  param_dropout param_batch_size  \\\n",
      "0 0.2            10                \n",
      "\n",
      "                                                                                                     params  \\\n",
      "0  {'nhidden2': 1, 'nhidden1': 1, 'nfirst': 10, 'lr': 0.1, 'epochs': 100, 'dropout': 0.2, 'batch_size': 10}   \n",
      "\n",
      "   split0_test_score  split1_test_score  mean_test_score  std_test_score  \\\n",
      "0 0.7096774194       0.7301587302       0.7199180748     0.0102406554      \n",
      "\n",
      "   rank_test_score  \n",
      "0  1                \n"
     ]
    }
   ],
   "source": [
    "n_iter = optiter\n",
    "\n",
    "if 'nn' in models or 'pnn' in models:\n",
    "    fixedparams = dict(scale_pos_weight=10, output_bias=0.9)\n",
    "    params = {'nhidden1': 5, 'nfirst': 10, 'epochs': 30, 'dropout': 0.2, 'batch_size': 10}\n",
    "    model = MyNN(**fixedparams, **params)\n",
    "    params = dict(\n",
    "        lr=[0.005, 0.1],\n",
    "        epochs=[100, 200],\n",
    "        batch_size=[10, 100],\n",
    "        nfirst=[10, 20, 100],\n",
    "        nhidden1=[1, 5, 20],\n",
    "        nhidden2=[0, 1, 5, 10],\n",
    "        dropout=[0.2, 0])\n",
    "    randcv = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=n_iter, scoring='f1', n_jobs=1,\n",
    "                                cv=cv, verbose=1, random_state=1).fit(dftrain[xs], dftrain[y])\n",
    "    print(\n",
    "        f\"rscv {model.__class__.__name__} fixedparams={fixedparams} bestscore={randcv.best_score_} bestparams={randcv.best_params_} \\n{DF(randcv.cv_results_).sort_values(by='mean_test_score', ascending=False)[['mean_test_score', 'std_test_score', 'params']]}\")\n",
    "    print(f\"rscv \\n{DF(randcv.cv_results_).sort_values(by='mean_test_score', ascending=False)}\")\n",
    "    nn = MyNN(**fixedparams, **randcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c3c9a7b0-6b61-4bcf-acd3-033ea61c24d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "rscv XGBClassifier fixedparams={'objective': 'binary:logistic'} bestscore=0.7199180747567844 bestparams={'scale_pos_weight': 100, 'n_estimators': 200, 'max_depth': 10, 'max_delta_step': 1, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'base_score': 0.9, 'alpha': 10} \n",
      "   mean_test_score  std_test_score  \\\n",
      "0 0.7199180748     0.0102406554      \n",
      "\n",
      "                                                                                                                                                                params  \n",
      "0  {'scale_pos_weight': 100, 'n_estimators': 200, 'max_depth': 10, 'max_delta_step': 1, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'base_score': 0.9, 'alpha': 10}  \n",
      "rscv \n",
      "   mean_fit_time   std_fit_time  mean_score_time  std_score_time  \\\n",
      "0 0.1096060276   0.001989603043 0.001994609833   0.001994609833    \n",
      "\n",
      "  param_scale_pos_weight param_n_estimators param_max_depth  \\\n",
      "0  100                    200                10               \n",
      "\n",
      "  param_max_delta_step param_learning_rate param_colsample_bytree  \\\n",
      "0  1                   0.1                 0.8                      \n",
      "\n",
      "  param_base_score param_alpha  \\\n",
      "0 0.9               10           \n",
      "\n",
      "                                                                                                                                                                params  \\\n",
      "0  {'scale_pos_weight': 100, 'n_estimators': 200, 'max_depth': 10, 'max_delta_step': 1, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'base_score': 0.9, 'alpha': 10}   \n",
      "\n",
      "   split0_test_score  split1_test_score  mean_test_score  std_test_score  \\\n",
      "0 0.7096774194       0.7301587302       0.7199180748     0.0102406554      \n",
      "\n",
      "   rank_test_score  \n",
      "0  1                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'xgbc' in models or 'pxgbc' in models:  # False:\n",
    "\n",
    "    params = {'scale_pos_weight': 100, 'n_estimators': 30, 'max_depth': 5, 'max_delta_step': 10, 'learning_rate': 0.1,\n",
    "              'colsample_bytree': 0.8, 'base_score': 0.1, 'alpha': 1}\n",
    "    fixedparams = dict(objective='binary:logistic')\n",
    "    model = xgb.XGBClassifier(**fixedparams, **params)\n",
    "    params = {\n",
    "        'n_estimators': [10, 100, 200],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'max_depth': [5, 10],\n",
    "        'learning_rate': [0.01, 0.1, 1],\n",
    "        'alpha': [1, 10, 100],\n",
    "        'scale_pos_weight': [1, 10, 100],\n",
    "        'base_score': [0.1, 0.9],\n",
    "        'max_delta_step': [0, 1, 10]\n",
    "    }\n",
    "    randcv = RandomizedSearchCV(model, param_distributions=params, n_iter=n_iter, scoring='f1', n_jobs=1, cv=cv,\n",
    "                                verbose=0, random_state=1).fit(dftrain[xs], dftrain[y])\n",
    "    print(\n",
    "        f\"rscv {model.__class__.__name__} fixedparams={fixedparams} bestscore={randcv.best_score_} bestparams={randcv.best_params_} \\n{DF(randcv.cv_results_).sort_values(by='mean_test_score', ascending=False)[['mean_test_score', 'std_test_score', 'params']]}\")\n",
    "    print(f\"rscv \\n{DF(randcv.cv_results_).sort_values(by='mean_test_score', ascending=False)}\")\n",
    "    xgbc = xgb.XGBClassifier(**fixedparams, **randcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b75f6cc9-1231-4c05-8ee8-ef8c02cfd71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:52:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:52:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:52:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "rscv XGBRFClassifier fixedparams={'objective': 'binary:logistic'} bestscore=0.7199180747567844 bestparams={'scale_pos_weight': 100, 'n_estimators': 200, 'max_depth': 10, 'max_delta_step': 1, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'base_score': 0.9, 'alpha': 10} \n",
      "   mean_test_score  std_test_score  \\\n",
      "0 0.7199180748     0.0102406554      \n",
      "\n",
      "                                                                                                                                                                params  \n",
      "0  {'scale_pos_weight': 100, 'n_estimators': 200, 'max_depth': 10, 'max_delta_step': 1, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'base_score': 0.9, 'alpha': 10}  \n",
      "rscv \n",
      "   mean_fit_time    std_fit_time  mean_score_time  std_score_time  \\\n",
      "0 0.0428853035   0.0009973049164 0.003989338875   1.192092896e-07   \n",
      "\n",
      "  param_scale_pos_weight param_n_estimators param_max_depth  \\\n",
      "0  100                    200                10               \n",
      "\n",
      "  param_max_delta_step param_learning_rate param_colsample_bytree  \\\n",
      "0  1                   0.1                 0.8                      \n",
      "\n",
      "  param_base_score param_alpha  \\\n",
      "0 0.9               10           \n",
      "\n",
      "                                                                                                                                                                params  \\\n",
      "0  {'scale_pos_weight': 100, 'n_estimators': 200, 'max_depth': 10, 'max_delta_step': 1, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'base_score': 0.9, 'alpha': 10}   \n",
      "\n",
      "   split0_test_score  split1_test_score  mean_test_score  std_test_score  \\\n",
      "0 0.7096774194       0.7301587302       0.7199180748     0.0102406554      \n",
      "\n",
      "   rank_test_score  \n",
      "0  1                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "C:\\Users\\Wang\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'xgbrf' in models or 'pxgbrf' in models:\n",
    "    params = {'scale_pos_weight': 100, 'n_estimators': 30, 'max_depth': 5, 'max_delta_step': 10, 'learning_rate': 0.1,\n",
    "              'colsample_bytree': 0.8, 'base_score': 0.1, 'alpha': 1}\n",
    "    fixedparams = dict(objective='binary:logistic')\n",
    "    model = xgb.XGBRFClassifier(**fixedparams, **params)\n",
    "    params = {\n",
    "        'n_estimators': [10, 100, 200],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'max_depth': [5, 10],\n",
    "        'learning_rate': [0.01, 0.1, 1],\n",
    "        'alpha': [1, 10, 100],\n",
    "        'scale_pos_weight': [1, 10, 100],\n",
    "        'base_score': [0.1, 0.9],\n",
    "        'max_delta_step': [0, 1, 10]\n",
    "    }\n",
    "    randcv = RandomizedSearchCV(model, param_distributions=params, n_iter=n_iter, scoring='f1', n_jobs=1, cv=cv,\n",
    "                                verbose=0, random_state=1).fit(dftrain[xs], dftrain[y])\n",
    "    print(\n",
    "        f\"rscv {model.__class__.__name__} fixedparams={fixedparams} bestscore={randcv.best_score_} bestparams={randcv.best_params_} \\n{DF(randcv.cv_results_).sort_values(by='mean_test_score', ascending=False)[['mean_test_score', 'std_test_score', 'params']]}\")\n",
    "    print(f\"rscv \\n{DF(randcv.cv_results_).sort_values(by='mean_test_score', ascending=False)}\")\n",
    "    xgbrf = xgb.XGBRFClassifier(**fixedparams, **randcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7c9b716c-82f6-4c92-9750-95082f2a7d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rscv MyLogisticRegression fixedparams={'penalty': 'l2', 'l1_ratio': None, 'class_weight': 'balanced', 'verbose': 0} bestscore=0.3548387096774194 bestparams={'tol': 0.001, 'solver': 'lbfgs', 'max_iter': 10, 'C': 1} \n",
      "   mean_test_score  std_test_score  \\\n",
      "0 0.3548387097     0.3548387097      \n",
      "\n",
      "                                                      params  \n",
      "0  {'tol': 0.001, 'solver': 'lbfgs', 'max_iter': 10, 'C': 1}  \n",
      "rscv \n",
      "   mean_fit_time    std_fit_time  mean_score_time  std_score_time param_tol  \\\n",
      "0 0.005003452301 0.0009815692902 0.002494692802   0.0004979372025 0.001       \n",
      "\n",
      "  param_solver param_max_iter param_C  \\\n",
      "0  lbfgs        10             1        \n",
      "\n",
      "                                                      params  \\\n",
      "0  {'tol': 0.001, 'solver': 'lbfgs', 'max_iter': 10, 'C': 1}   \n",
      "\n",
      "   split0_test_score  split1_test_score  mean_test_score  std_test_score  \\\n",
      "0 0.7096774194       0                  0.3548387097     0.3548387097      \n",
      "\n",
      "   rank_test_score  \n",
      "0  1                \n"
     ]
    }
   ],
   "source": [
    "if 'log' in models or 'plog' in models:  # False:\n",
    "    params = dict(tol=0.0001, C=1.0, solver='saga', max_iter=300)\n",
    "    fixedparams = dict(penalty='l2', l1_ratio=None, class_weight='balanced', verbose=0)\n",
    "    model = MyLogisticRegression(**fixedparams, **params)  # solver='lbfgs'\n",
    "    # model=Pipeline([(\"pipe0\",StandardScaler()),(\"pipe1\",modellogistic)])\n",
    "    # for pipelione need prefix pipe1!\n",
    "    params = {\n",
    "        'tol': [0.0001, 0.001, 0.01],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'max_iter': [10, 50, 100, 300],\n",
    "        'solver': ['lbfgs', 'sag', 'saga']\n",
    "    }\n",
    "\n",
    "    randcv = RandomizedSearchCV(model, param_distributions=params, n_iter=n_iter, scoring='f1', n_jobs=1, cv=cv,\n",
    "                                verbose=0, random_state=1).fit(dftrain[xs], dftrain[y])\n",
    "    print(\n",
    "        f\"rscv {model.__class__.__name__} fixedparams={fixedparams} bestscore={randcv.best_score_} bestparams={randcv.best_params_} \\n{DF(randcv.cv_results_).sort_values(by='mean_test_score', ascending=False)[['mean_test_score', 'std_test_score', 'params']]}\")\n",
    "    print(f\"rscv \\n{DF(randcv.cv_results_).sort_values(by='mean_test_score', ascending=False)}\")\n",
    "    log = MyLogisticRegression(**fixedparams, **randcv.best_params_)  # solver='lbfgs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7e6b1537-b0d6-415d-8036-6eb728689084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmodel(modelname):\n",
    "    if modelname[0] == 'p':\n",
    "        return Pipeline([(\"pipe0\", StandardScaler()), (\"pipe1\", eval(modelname[1:]))])\n",
    "    else:\n",
    "        return eval(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294a03f-42de-4d09-b1f9-ed9f596e2c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4c35f-92a0-44a7-ac1e-51d0d106e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mstr in models:\n",
    "    runselector(dftrain, y=y, xs=xs, model=getmodel(mstr), nansy='.fillna(0)', nansx=None, verbose=2,\n",
    "                methods=['sfsb', 'sfsf', 'rfe', 'abscoef'], dftest=dftest, scoring='f1', eval_metric='f1', cv=cv)  # ,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2673728-0151-48de-b3ad-57d0a029e3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
